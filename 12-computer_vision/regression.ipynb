{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkl-random 1.0.1 requires cython, which is not installed.\n",
      "tensorflow 1.10.0 has requirement numpy<=1.14.5,>=1.13.3, but you'll have numpy 1.19.5 which is incompatible.\n",
      "tensorflow 1.10.0 has requirement setuptools<=39.1.0, but you'll have setuptools 58.0.4 which is incompatible.\n",
      "You are using pip version 10.0.1, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading https://files.pythonhosted.org/packages/79/87/8bb36bd4ebae147612c73d1bdc1385db7beebb9eb141c4bfefb33f52c87c/pandas-1.1.5-cp36-cp36m-win_amd64.whl (8.7MB)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\yashraj\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages (from pandas) (2021.3)\n",
      "Collecting numpy>=1.15.4 (from pandas)\n",
      "  Downloading https://files.pythonhosted.org/packages/ea/bc/da526221bc111857c7ef39c3af670bbcf5e69c247b0d22e51986f6d0c5c2/numpy-1.19.5-cp36-cp36m-win_amd64.whl (13.2MB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\yashraj\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yashraj\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.11.0)\n",
      "Installing collected packages: numpy, pandas\n",
      "  Found existing installation: numpy 1.15.1\n",
      "    Uninstalling numpy-1.15.1:\n",
      "      Successfully uninstalled numpy-1.15.1\n",
      "Successfully installed numpy-1.19.5 pandas-1.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python -m pip install --upgrade pip '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'python -m pip install --upgrade pip '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"c:/Data-Science/13-deep_learning/kc_house_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "date             0\n",
       "price            0\n",
       "bedrooms         0\n",
       "bathrooms        0\n",
       "sqft_living      0\n",
       "sqft_lot         0\n",
       "floors           0\n",
       "waterfront       0\n",
       "view             0\n",
       "condition        0\n",
       "grade            0\n",
       "sqft_above       0\n",
       "sqft_basement    0\n",
       "yr_built         0\n",
       "yr_renovated     0\n",
       "zipcode          0\n",
       "lat              0\n",
       "long             0\n",
       "sqft_living15    0\n",
       "sqft_lot15       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>21597.0</td>\n",
       "      <td>4.580474e+09</td>\n",
       "      <td>2.876736e+09</td>\n",
       "      <td>1.000102e+06</td>\n",
       "      <td>2.123049e+09</td>\n",
       "      <td>3.904930e+09</td>\n",
       "      <td>7.308900e+09</td>\n",
       "      <td>9.900000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>21597.0</td>\n",
       "      <td>5.402966e+05</td>\n",
       "      <td>3.673681e+05</td>\n",
       "      <td>7.800000e+04</td>\n",
       "      <td>3.220000e+05</td>\n",
       "      <td>4.500000e+05</td>\n",
       "      <td>6.450000e+05</td>\n",
       "      <td>7.700000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>21597.0</td>\n",
       "      <td>3.373200e+00</td>\n",
       "      <td>9.262989e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>3.300000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms</th>\n",
       "      <td>21597.0</td>\n",
       "      <td>2.115826e+00</td>\n",
       "      <td>7.689843e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>1.750000e+00</td>\n",
       "      <td>2.250000e+00</td>\n",
       "      <td>2.500000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_living</th>\n",
       "      <td>21597.0</td>\n",
       "      <td>2.080322e+03</td>\n",
       "      <td>9.181061e+02</td>\n",
       "      <td>3.700000e+02</td>\n",
       "      <td>1.430000e+03</td>\n",
       "      <td>1.910000e+03</td>\n",
       "      <td>2.550000e+03</td>\n",
       "      <td>1.354000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_lot</th>\n",
       "      <td>21597.0</td>\n",
       "      <td>1.509941e+04</td>\n",
       "      <td>4.141264e+04</td>\n",
       "      <td>5.200000e+02</td>\n",
       "      <td>5.040000e+03</td>\n",
       "      <td>7.618000e+03</td>\n",
       "      <td>1.068500e+04</td>\n",
       "      <td>1.651359e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floors</th>\n",
       "      <td>21597.0</td>\n",
       "      <td>1.494096e+00</td>\n",
       "      <td>5.396828e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.500000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.500000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waterfront</th>\n",
       "      <td>21597.0</td>\n",
       "      <td>7.547345e-03</td>\n",
       "      <td>8.654900e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>view</th>\n",
       "      <td>21597.0</td>\n",
       "      <td>2.342918e-01</td>\n",
       "      <td>7.663898e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>condition</th>\n",
       "      <td>21597.0</td>\n",
       "      <td>3.409825e+00</td>\n",
       "      <td>6.505456e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade</th>\n",
       "      <td>21597.0</td>\n",
       "      <td>7.657915e+00</td>\n",
       "      <td>1.173200e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>1.300000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_above</th>\n",
       "      <td>21597.0</td>\n",
       "      <td>1.788597e+03</td>\n",
       "      <td>8.277598e+02</td>\n",
       "      <td>3.700000e+02</td>\n",
       "      <td>1.190000e+03</td>\n",
       "      <td>1.560000e+03</td>\n",
       "      <td>2.210000e+03</td>\n",
       "      <td>9.410000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_basement</th>\n",
       "      <td>21597.0</td>\n",
       "      <td>2.917250e+02</td>\n",
       "      <td>4.426678e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.600000e+02</td>\n",
       "      <td>4.820000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yr_built</th>\n",
       "      <td>21597.0</td>\n",
       "      <td>1.971000e+03</td>\n",
       "      <td>2.937523e+01</td>\n",
       "      <td>1.900000e+03</td>\n",
       "      <td>1.951000e+03</td>\n",
       "      <td>1.975000e+03</td>\n",
       "      <td>1.997000e+03</td>\n",
       "      <td>2.015000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yr_renovated</th>\n",
       "      <td>21597.0</td>\n",
       "      <td>8.446479e+01</td>\n",
       "      <td>4.018214e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.015000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode</th>\n",
       "      <td>21597.0</td>\n",
       "      <td>9.807795e+04</td>\n",
       "      <td>5.351307e+01</td>\n",
       "      <td>9.800100e+04</td>\n",
       "      <td>9.803300e+04</td>\n",
       "      <td>9.806500e+04</td>\n",
       "      <td>9.811800e+04</td>\n",
       "      <td>9.819900e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lat</th>\n",
       "      <td>21597.0</td>\n",
       "      <td>4.756009e+01</td>\n",
       "      <td>1.385518e-01</td>\n",
       "      <td>4.715590e+01</td>\n",
       "      <td>4.747110e+01</td>\n",
       "      <td>4.757180e+01</td>\n",
       "      <td>4.767800e+01</td>\n",
       "      <td>4.777760e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long</th>\n",
       "      <td>21597.0</td>\n",
       "      <td>-1.222140e+02</td>\n",
       "      <td>1.407235e-01</td>\n",
       "      <td>-1.225190e+02</td>\n",
       "      <td>-1.223280e+02</td>\n",
       "      <td>-1.222310e+02</td>\n",
       "      <td>-1.221250e+02</td>\n",
       "      <td>-1.213150e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_living15</th>\n",
       "      <td>21597.0</td>\n",
       "      <td>1.986620e+03</td>\n",
       "      <td>6.852305e+02</td>\n",
       "      <td>3.990000e+02</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.840000e+03</td>\n",
       "      <td>2.360000e+03</td>\n",
       "      <td>6.210000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_lot15</th>\n",
       "      <td>21597.0</td>\n",
       "      <td>1.275828e+04</td>\n",
       "      <td>2.727444e+04</td>\n",
       "      <td>6.510000e+02</td>\n",
       "      <td>5.100000e+03</td>\n",
       "      <td>7.620000e+03</td>\n",
       "      <td>1.008300e+04</td>\n",
       "      <td>8.712000e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count          mean           std           min  \\\n",
       "id             21597.0  4.580474e+09  2.876736e+09  1.000102e+06   \n",
       "price          21597.0  5.402966e+05  3.673681e+05  7.800000e+04   \n",
       "bedrooms       21597.0  3.373200e+00  9.262989e-01  1.000000e+00   \n",
       "bathrooms      21597.0  2.115826e+00  7.689843e-01  5.000000e-01   \n",
       "sqft_living    21597.0  2.080322e+03  9.181061e+02  3.700000e+02   \n",
       "sqft_lot       21597.0  1.509941e+04  4.141264e+04  5.200000e+02   \n",
       "floors         21597.0  1.494096e+00  5.396828e-01  1.000000e+00   \n",
       "waterfront     21597.0  7.547345e-03  8.654900e-02  0.000000e+00   \n",
       "view           21597.0  2.342918e-01  7.663898e-01  0.000000e+00   \n",
       "condition      21597.0  3.409825e+00  6.505456e-01  1.000000e+00   \n",
       "grade          21597.0  7.657915e+00  1.173200e+00  3.000000e+00   \n",
       "sqft_above     21597.0  1.788597e+03  8.277598e+02  3.700000e+02   \n",
       "sqft_basement  21597.0  2.917250e+02  4.426678e+02  0.000000e+00   \n",
       "yr_built       21597.0  1.971000e+03  2.937523e+01  1.900000e+03   \n",
       "yr_renovated   21597.0  8.446479e+01  4.018214e+02  0.000000e+00   \n",
       "zipcode        21597.0  9.807795e+04  5.351307e+01  9.800100e+04   \n",
       "lat            21597.0  4.756009e+01  1.385518e-01  4.715590e+01   \n",
       "long           21597.0 -1.222140e+02  1.407235e-01 -1.225190e+02   \n",
       "sqft_living15  21597.0  1.986620e+03  6.852305e+02  3.990000e+02   \n",
       "sqft_lot15     21597.0  1.275828e+04  2.727444e+04  6.510000e+02   \n",
       "\n",
       "                        25%           50%           75%           max  \n",
       "id             2.123049e+09  3.904930e+09  7.308900e+09  9.900000e+09  \n",
       "price          3.220000e+05  4.500000e+05  6.450000e+05  7.700000e+06  \n",
       "bedrooms       3.000000e+00  3.000000e+00  4.000000e+00  3.300000e+01  \n",
       "bathrooms      1.750000e+00  2.250000e+00  2.500000e+00  8.000000e+00  \n",
       "sqft_living    1.430000e+03  1.910000e+03  2.550000e+03  1.354000e+04  \n",
       "sqft_lot       5.040000e+03  7.618000e+03  1.068500e+04  1.651359e+06  \n",
       "floors         1.000000e+00  1.500000e+00  2.000000e+00  3.500000e+00  \n",
       "waterfront     0.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00  \n",
       "view           0.000000e+00  0.000000e+00  0.000000e+00  4.000000e+00  \n",
       "condition      3.000000e+00  3.000000e+00  4.000000e+00  5.000000e+00  \n",
       "grade          7.000000e+00  7.000000e+00  8.000000e+00  1.300000e+01  \n",
       "sqft_above     1.190000e+03  1.560000e+03  2.210000e+03  9.410000e+03  \n",
       "sqft_basement  0.000000e+00  0.000000e+00  5.600000e+02  4.820000e+03  \n",
       "yr_built       1.951000e+03  1.975000e+03  1.997000e+03  2.015000e+03  \n",
       "yr_renovated   0.000000e+00  0.000000e+00  0.000000e+00  2.015000e+03  \n",
       "zipcode        9.803300e+04  9.806500e+04  9.811800e+04  9.819900e+04  \n",
       "lat            4.747110e+01  4.757180e+01  4.767800e+01  4.777760e+01  \n",
       "long          -1.223280e+02 -1.222310e+02 -1.221250e+02 -1.213150e+02  \n",
       "sqft_living15  1.490000e+03  1.840000e+03  2.360000e+03  6.210000e+03  \n",
       "sqft_lot15     5.100000e+03  7.620000e+03  1.008300e+04  8.712000e+05  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7245</th>\n",
       "      <td>6762700020</td>\n",
       "      <td>10/13/2014</td>\n",
       "      <td>7700000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>8.00</td>\n",
       "      <td>12050</td>\n",
       "      <td>27600</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>8570</td>\n",
       "      <td>3480</td>\n",
       "      <td>1910</td>\n",
       "      <td>1987</td>\n",
       "      <td>98102</td>\n",
       "      <td>47.6298</td>\n",
       "      <td>-122.323</td>\n",
       "      <td>3940</td>\n",
       "      <td>8800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3910</th>\n",
       "      <td>9808700762</td>\n",
       "      <td>6/11/2014</td>\n",
       "      <td>7060000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.50</td>\n",
       "      <td>10040</td>\n",
       "      <td>37325</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>7680</td>\n",
       "      <td>2360</td>\n",
       "      <td>1940</td>\n",
       "      <td>2001</td>\n",
       "      <td>98004</td>\n",
       "      <td>47.6500</td>\n",
       "      <td>-122.214</td>\n",
       "      <td>3930</td>\n",
       "      <td>25449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9245</th>\n",
       "      <td>9208900037</td>\n",
       "      <td>9/19/2014</td>\n",
       "      <td>6890000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7.75</td>\n",
       "      <td>9890</td>\n",
       "      <td>31374</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>8860</td>\n",
       "      <td>1030</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>98039</td>\n",
       "      <td>47.6305</td>\n",
       "      <td>-122.240</td>\n",
       "      <td>4540</td>\n",
       "      <td>42730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4407</th>\n",
       "      <td>2470100110</td>\n",
       "      <td>8/4/2014</td>\n",
       "      <td>5570000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.75</td>\n",
       "      <td>9200</td>\n",
       "      <td>35069</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>6200</td>\n",
       "      <td>3000</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>98039</td>\n",
       "      <td>47.6289</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>3560</td>\n",
       "      <td>24345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>8907500070</td>\n",
       "      <td>4/13/2015</td>\n",
       "      <td>5350000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.00</td>\n",
       "      <td>8000</td>\n",
       "      <td>23985</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>6720</td>\n",
       "      <td>1280</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98004</td>\n",
       "      <td>47.6232</td>\n",
       "      <td>-122.220</td>\n",
       "      <td>4600</td>\n",
       "      <td>21750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>7558700030</td>\n",
       "      <td>4/13/2015</td>\n",
       "      <td>5300000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7390</td>\n",
       "      <td>24829</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>5000</td>\n",
       "      <td>2390</td>\n",
       "      <td>1991</td>\n",
       "      <td>0</td>\n",
       "      <td>98040</td>\n",
       "      <td>47.5631</td>\n",
       "      <td>-122.210</td>\n",
       "      <td>4320</td>\n",
       "      <td>24619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>1247600105</td>\n",
       "      <td>10/20/2014</td>\n",
       "      <td>5110000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.25</td>\n",
       "      <td>8010</td>\n",
       "      <td>45517</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>5990</td>\n",
       "      <td>2020</td>\n",
       "      <td>1999</td>\n",
       "      <td>0</td>\n",
       "      <td>98033</td>\n",
       "      <td>47.6767</td>\n",
       "      <td>-122.211</td>\n",
       "      <td>3430</td>\n",
       "      <td>26788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8085</th>\n",
       "      <td>1924059029</td>\n",
       "      <td>6/17/2014</td>\n",
       "      <td>4670000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6.75</td>\n",
       "      <td>9640</td>\n",
       "      <td>13068</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>4820</td>\n",
       "      <td>4820</td>\n",
       "      <td>1983</td>\n",
       "      <td>2009</td>\n",
       "      <td>98040</td>\n",
       "      <td>47.5570</td>\n",
       "      <td>-122.210</td>\n",
       "      <td>3270</td>\n",
       "      <td>10454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>7738500731</td>\n",
       "      <td>8/15/2014</td>\n",
       "      <td>4500000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.50</td>\n",
       "      <td>6640</td>\n",
       "      <td>40014</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>6350</td>\n",
       "      <td>290</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>98155</td>\n",
       "      <td>47.7493</td>\n",
       "      <td>-122.280</td>\n",
       "      <td>3030</td>\n",
       "      <td>23408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8629</th>\n",
       "      <td>3835500195</td>\n",
       "      <td>6/18/2014</td>\n",
       "      <td>4490000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6430</td>\n",
       "      <td>27517</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>6430</td>\n",
       "      <td>0</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>98004</td>\n",
       "      <td>47.6208</td>\n",
       "      <td>-122.219</td>\n",
       "      <td>3720</td>\n",
       "      <td>14592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12358</th>\n",
       "      <td>6065300370</td>\n",
       "      <td>5/6/2015</td>\n",
       "      <td>4210000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7440</td>\n",
       "      <td>21540</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>5550</td>\n",
       "      <td>1890</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>98006</td>\n",
       "      <td>47.5692</td>\n",
       "      <td>-122.189</td>\n",
       "      <td>4740</td>\n",
       "      <td>19329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4145</th>\n",
       "      <td>6447300265</td>\n",
       "      <td>10/14/2014</td>\n",
       "      <td>4000000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.50</td>\n",
       "      <td>7080</td>\n",
       "      <td>16573</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>5760</td>\n",
       "      <td>1320</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98039</td>\n",
       "      <td>47.6151</td>\n",
       "      <td>-122.224</td>\n",
       "      <td>3140</td>\n",
       "      <td>15996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>8106100105</td>\n",
       "      <td>11/14/2014</td>\n",
       "      <td>3850000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.25</td>\n",
       "      <td>5770</td>\n",
       "      <td>21300</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>5770</td>\n",
       "      <td>0</td>\n",
       "      <td>1980</td>\n",
       "      <td>0</td>\n",
       "      <td>98040</td>\n",
       "      <td>47.5850</td>\n",
       "      <td>-122.222</td>\n",
       "      <td>4620</td>\n",
       "      <td>22748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7028</th>\n",
       "      <td>853200010</td>\n",
       "      <td>7/1/2014</td>\n",
       "      <td>3800000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.50</td>\n",
       "      <td>7050</td>\n",
       "      <td>42840</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>4320</td>\n",
       "      <td>2730</td>\n",
       "      <td>1978</td>\n",
       "      <td>0</td>\n",
       "      <td>98004</td>\n",
       "      <td>47.6229</td>\n",
       "      <td>-122.220</td>\n",
       "      <td>5070</td>\n",
       "      <td>20570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19002</th>\n",
       "      <td>2303900100</td>\n",
       "      <td>9/11/2014</td>\n",
       "      <td>3800000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.25</td>\n",
       "      <td>5510</td>\n",
       "      <td>35000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>4910</td>\n",
       "      <td>600</td>\n",
       "      <td>1997</td>\n",
       "      <td>0</td>\n",
       "      <td>98177</td>\n",
       "      <td>47.7296</td>\n",
       "      <td>-122.370</td>\n",
       "      <td>3430</td>\n",
       "      <td>45302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16288</th>\n",
       "      <td>7397300170</td>\n",
       "      <td>5/30/2014</td>\n",
       "      <td>3710000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.50</td>\n",
       "      <td>5550</td>\n",
       "      <td>28078</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>3350</td>\n",
       "      <td>2200</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>98039</td>\n",
       "      <td>47.6395</td>\n",
       "      <td>-122.234</td>\n",
       "      <td>2980</td>\n",
       "      <td>19602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18467</th>\n",
       "      <td>4389201095</td>\n",
       "      <td>5/11/2015</td>\n",
       "      <td>3650000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.75</td>\n",
       "      <td>5020</td>\n",
       "      <td>8694</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>3970</td>\n",
       "      <td>1050</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>98004</td>\n",
       "      <td>47.6146</td>\n",
       "      <td>-122.213</td>\n",
       "      <td>4190</td>\n",
       "      <td>11275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6502</th>\n",
       "      <td>4217402115</td>\n",
       "      <td>4/21/2015</td>\n",
       "      <td>3650000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.75</td>\n",
       "      <td>5480</td>\n",
       "      <td>19401</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>3910</td>\n",
       "      <td>1570</td>\n",
       "      <td>1936</td>\n",
       "      <td>0</td>\n",
       "      <td>98105</td>\n",
       "      <td>47.6515</td>\n",
       "      <td>-122.277</td>\n",
       "      <td>3510</td>\n",
       "      <td>15810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15241</th>\n",
       "      <td>2425049063</td>\n",
       "      <td>9/11/2014</td>\n",
       "      <td>3640000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4830</td>\n",
       "      <td>22257</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>4830</td>\n",
       "      <td>0</td>\n",
       "      <td>1990</td>\n",
       "      <td>0</td>\n",
       "      <td>98039</td>\n",
       "      <td>47.6409</td>\n",
       "      <td>-122.241</td>\n",
       "      <td>3820</td>\n",
       "      <td>25582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19133</th>\n",
       "      <td>3625049042</td>\n",
       "      <td>10/11/2014</td>\n",
       "      <td>3640000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5490</td>\n",
       "      <td>19897</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>5490</td>\n",
       "      <td>0</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>98039</td>\n",
       "      <td>47.6165</td>\n",
       "      <td>-122.236</td>\n",
       "      <td>2910</td>\n",
       "      <td>17600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id        date      price  bedrooms  bathrooms  sqft_living  \\\n",
       "7245   6762700020  10/13/2014  7700000.0         6       8.00        12050   \n",
       "3910   9808700762   6/11/2014  7060000.0         5       4.50        10040   \n",
       "9245   9208900037   9/19/2014  6890000.0         6       7.75         9890   \n",
       "4407   2470100110    8/4/2014  5570000.0         5       5.75         9200   \n",
       "1446   8907500070   4/13/2015  5350000.0         5       5.00         8000   \n",
       "1313   7558700030   4/13/2015  5300000.0         6       6.00         7390   \n",
       "1162   1247600105  10/20/2014  5110000.0         5       5.25         8010   \n",
       "8085   1924059029   6/17/2014  4670000.0         5       6.75         9640   \n",
       "2624   7738500731   8/15/2014  4500000.0         5       5.50         6640   \n",
       "8629   3835500195   6/18/2014  4490000.0         4       3.00         6430   \n",
       "12358  6065300370    5/6/2015  4210000.0         5       6.00         7440   \n",
       "4145   6447300265  10/14/2014  4000000.0         4       5.50         7080   \n",
       "2083   8106100105  11/14/2014  3850000.0         4       4.25         5770   \n",
       "7028    853200010    7/1/2014  3800000.0         5       5.50         7050   \n",
       "19002  2303900100   9/11/2014  3800000.0         3       4.25         5510   \n",
       "16288  7397300170   5/30/2014  3710000.0         4       3.50         5550   \n",
       "18467  4389201095   5/11/2015  3650000.0         5       3.75         5020   \n",
       "6502   4217402115   4/21/2015  3650000.0         6       4.75         5480   \n",
       "15241  2425049063   9/11/2014  3640000.0         4       3.25         4830   \n",
       "19133  3625049042  10/11/2014  3640000.0         5       6.00         5490   \n",
       "\n",
       "       sqft_lot  floors  waterfront  view  ...  grade  sqft_above  \\\n",
       "7245      27600     2.5           0     3  ...     13        8570   \n",
       "3910      37325     2.0           1     2  ...     11        7680   \n",
       "9245      31374     2.0           0     4  ...     13        8860   \n",
       "4407      35069     2.0           0     0  ...     13        6200   \n",
       "1446      23985     2.0           0     4  ...     12        6720   \n",
       "1313      24829     2.0           1     4  ...     12        5000   \n",
       "1162      45517     2.0           1     4  ...     12        5990   \n",
       "8085      13068     1.0           1     4  ...     12        4820   \n",
       "2624      40014     2.0           1     4  ...     12        6350   \n",
       "8629      27517     2.0           0     0  ...     12        6430   \n",
       "12358     21540     2.0           0     0  ...     12        5550   \n",
       "4145      16573     2.0           0     0  ...     12        5760   \n",
       "2083      21300     2.0           1     4  ...     11        5770   \n",
       "7028      42840     1.0           0     2  ...     13        4320   \n",
       "19002     35000     2.0           0     4  ...     13        4910   \n",
       "16288     28078     2.0           0     2  ...     12        3350   \n",
       "18467      8694     2.0           0     1  ...     12        3970   \n",
       "6502      19401     1.5           1     4  ...     11        3910   \n",
       "15241     22257     2.0           1     4  ...     11        4830   \n",
       "19133     19897     2.0           0     0  ...     12        5490   \n",
       "\n",
       "       sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "7245            3480      1910          1987    98102  47.6298 -122.323   \n",
       "3910            2360      1940          2001    98004  47.6500 -122.214   \n",
       "9245            1030      2001             0    98039  47.6305 -122.240   \n",
       "4407            3000      2001             0    98039  47.6289 -122.233   \n",
       "1446            1280      2009             0    98004  47.6232 -122.220   \n",
       "1313            2390      1991             0    98040  47.5631 -122.210   \n",
       "1162            2020      1999             0    98033  47.6767 -122.211   \n",
       "8085            4820      1983          2009    98040  47.5570 -122.210   \n",
       "2624             290      2004             0    98155  47.7493 -122.280   \n",
       "8629               0      2001             0    98004  47.6208 -122.219   \n",
       "12358           1890      2003             0    98006  47.5692 -122.189   \n",
       "4145            1320      2008             0    98039  47.6151 -122.224   \n",
       "2083               0      1980             0    98040  47.5850 -122.222   \n",
       "7028            2730      1978             0    98004  47.6229 -122.220   \n",
       "19002            600      1997             0    98177  47.7296 -122.370   \n",
       "16288           2200      2000             0    98039  47.6395 -122.234   \n",
       "18467           1050      2007             0    98004  47.6146 -122.213   \n",
       "6502            1570      1936             0    98105  47.6515 -122.277   \n",
       "15241              0      1990             0    98039  47.6409 -122.241   \n",
       "19133              0      2005             0    98039  47.6165 -122.236   \n",
       "\n",
       "       sqft_living15  sqft_lot15  \n",
       "7245            3940        8800  \n",
       "3910            3930       25449  \n",
       "9245            4540       42730  \n",
       "4407            3560       24345  \n",
       "1446            4600       21750  \n",
       "1313            4320       24619  \n",
       "1162            3430       26788  \n",
       "8085            3270       10454  \n",
       "2624            3030       23408  \n",
       "8629            3720       14592  \n",
       "12358           4740       19329  \n",
       "4145            3140       15996  \n",
       "2083            4620       22748  \n",
       "7028            5070       20570  \n",
       "19002           3430       45302  \n",
       "16288           2980       19602  \n",
       "18467           4190       11275  \n",
       "6502            3510       15810  \n",
       "15241           3820       25582  \n",
       "19133           2910       17600  \n",
       "\n",
       "[20 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(\"price\",ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['id'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-17afce2987f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4172\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4173\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4174\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4175\u001b[0m         )\n\u001b[0;32m   4176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3887\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3888\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3889\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3891\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3921\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3922\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3923\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3924\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3925\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5285\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5286\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5287\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5288\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5289\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['id'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df=df.drop(\"id\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"date\"]=pd.to_datetime(df[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"month\"]=df[\"date\"].apply(lambda date:date.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"year\"]=df[\"date\"].apply(lambda date:date.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(\"date\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',\n",
       "       'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n",
       "       'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long',\n",
       "       'sqft_living15', 'sqft_lot15', 'month', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(\"zipcode\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(\"price\",axis=1)\n",
    "y=df[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6480, 19)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6480, 19)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yashraj\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Yashraj\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Yashraj\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Yashraj\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Yashraj\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Yashraj\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#create a model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(Dense(19,activation=\"relu\"))\n",
    "model.add(Dense(19,activation=\"relu\"))\n",
    "model.add(Dense(19,activation=\"relu\"))\n",
    "model.add(Dense(19,activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer=\"adam\",loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15117 samples, validate on 6480 samples\n",
      "Epoch 1/400\n",
      "15117/15117 [==============================] - 1s 76us/step - loss: 430236525608.8462 - val_loss: 418897874286.6173\n",
      "Epoch 2/400\n",
      "15117/15117 [==============================] - 0s 23us/step - loss: 428999151466.1628 - val_loss: 414669223435.3778\n",
      "Epoch 3/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 412579955714.3708 - val_loss: 377726351749.3729\n",
      "Epoch 4/400\n",
      "15117/15117 [==============================] - 0s 21us/step - loss: 334550584190.5521 - val_loss: 254031707553.1852\n",
      "Epoch 5/400\n",
      "15117/15117 [==============================] - 0s 15us/step - loss: 184703142015.2126 - val_loss: 116165160666.7062\n",
      "Epoch 6/400\n",
      "15117/15117 [==============================] - 0s 14us/step - loss: 104288081263.8867 - val_loss: 94993501237.0963\n",
      "Epoch 7/400\n",
      "15117/15117 [==============================] - 0s 15us/step - loss: 97355802678.0552 - val_loss: 93489954957.5901\n",
      "Epoch 8/400\n",
      "15117/15117 [==============================] - 0s 16us/step - loss: 95713673511.8809 - val_loss: 91962800527.4864\n",
      "Epoch 9/400\n",
      "15117/15117 [==============================] - 0s 24us/step - loss: 94119422523.0339 - val_loss: 90423506898.4889\n",
      "Epoch 10/400\n",
      "15117/15117 [==============================] - 0s 19us/step - loss: 92448583764.4019 - val_loss: 88809512029.5506\n",
      "Epoch 11/400\n",
      "15117/15117 [==============================] - 0s 23us/step - loss: 90799307180.2416 - val_loss: 87254255064.8099\n",
      "Epoch 12/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 89075468839.2543 - val_loss: 85531577043.1210\n",
      "Epoch 13/400\n",
      "15117/15117 [==============================] - 0s 24us/step - loss: 87315991994.5344 - val_loss: 83780901627.5753\n",
      "Epoch 14/400\n",
      "15117/15117 [==============================] - 0s 15us/step - loss: 85429821837.4884 - val_loss: 82039043565.0370\n",
      "Epoch 15/400\n",
      "15117/15117 [==============================] - 0s 19us/step - loss: 83523024082.7339 - val_loss: 80113674497.8963\n",
      "Epoch 16/400\n",
      "15117/15117 [==============================] - 0s 22us/step - loss: 81498491795.6864 - val_loss: 78123224167.6642\n",
      "Epoch 17/400\n",
      "15117/15117 [==============================] - 0s 22us/step - loss: 79417928803.9140 - val_loss: 76091228756.7012\n",
      "Epoch 18/400\n",
      "15117/15117 [==============================] - 0s 17us/step - loss: 77257498538.9207 - val_loss: 73956363873.3432\n",
      "Epoch 19/400\n",
      "15117/15117 [==============================] - 0s 22us/step - loss: 74994015474.0290 - val_loss: 71777993705.2444\n",
      "Epoch 20/400\n",
      "15117/15117 [==============================] - 0s 23us/step - loss: 72633227331.8738 - val_loss: 69558732188.1284\n",
      "Epoch 21/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 70237271133.1402 - val_loss: 67156661164.5630\n",
      "Epoch 22/400\n",
      "15117/15117 [==============================] - 0s 28us/step - loss: 67815529220.4877 - val_loss: 64846078771.2000\n",
      "Epoch 23/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 65428162573.4122 - val_loss: 62551308687.4864\n",
      "Epoch 24/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 63095847156.9417 - val_loss: 60263545089.8963\n",
      "Epoch 25/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 60886103149.9393 - val_loss: 58173518279.1111\n",
      "Epoch 26/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 58743490412.8724 - val_loss: 56301810129.2247\n",
      "Epoch 27/400\n",
      "15117/15117 [==============================] - 0s 23us/step - loss: 56943258934.9866 - val_loss: 54694428854.0444\n",
      "Epoch 28/400\n",
      "15117/15117 [==============================] - 0s 24us/step - loss: 55348038184.3382 - val_loss: 53250444093.3136\n",
      "Epoch 29/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 54007666414.2695 - val_loss: 52070065169.6988\n",
      "Epoch 30/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 52842991193.1097 - val_loss: 51023910876.6025\n",
      "Epoch 31/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 51927738341.0402 - val_loss: 50231272541.5506\n",
      "Epoch 32/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 51075144108.2416 - val_loss: 49462761360.7506\n",
      "Epoch 33/400\n",
      "15117/15117 [==============================] - 0s 24us/step - loss: 50323609055.5195 - val_loss: 48791355872.3951\n",
      "Epoch 34/400\n",
      "15117/15117 [==============================] - 0s 17us/step - loss: 49697676315.5695 - val_loss: 48209433577.2444\n",
      "Epoch 35/400\n",
      "15117/15117 [==============================] - 0s 23us/step - loss: 49103434768.1895 - val_loss: 47717995249.4617\n",
      "Epoch 36/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 48607981911.7042 - val_loss: 47190861829.0568\n",
      "Epoch 37/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 48090746673.4659 - val_loss: 46728837544.7704\n",
      "Epoch 38/400\n",
      "15117/15117 [==============================] - 0s 22us/step - loss: 47609069044.1797 - val_loss: 46371437368.2568\n",
      "Epoch 39/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 47168116592.6657 - val_loss: 45949243619.5556\n",
      "Epoch 40/400\n",
      "15117/15117 [==============================] - 0s 21us/step - loss: 46777089043.8473 - val_loss: 45493701674.9827\n",
      "Epoch 41/400\n",
      "15117/15117 [==============================] - 0s 15us/step - loss: 46400468691.0387 - val_loss: 45116282536.1383\n",
      "Epoch 42/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 46009888402.2131 - val_loss: 44810558061.9852\n",
      "Epoch 43/400\n",
      "15117/15117 [==============================] - 0s 16us/step - loss: 45673219905.3167 - val_loss: 44565442261.6494\n",
      "Epoch 44/400\n",
      "15117/15117 [==============================] - 0s 17us/step - loss: 45333862882.4322 - val_loss: 44108946864.3556\n",
      "Epoch 45/400\n",
      "15117/15117 [==============================] - 0s 15us/step - loss: 44995850352.9875 - val_loss: 43792545175.0716\n",
      "Epoch 46/400\n",
      "15117/15117 [==============================] - 0s 16us/step - loss: 44668032571.6436 - val_loss: 43485596947.5951\n",
      "Epoch 47/400\n",
      "15117/15117 [==============================] - 0s 16us/step - loss: 44377638421.1682 - val_loss: 43319692993.4222\n",
      "Epoch 48/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 44067596585.7776 - val_loss: 42878008514.6864\n",
      "Epoch 49/400\n",
      "15117/15117 [==============================] - 0s 19us/step - loss: 43737404627.4790 - val_loss: 42596631190.4395\n",
      "Epoch 50/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 43427662592.8298 - val_loss: 42243254140.5235\n",
      "Epoch 51/400\n",
      "15117/15117 [==============================] - 0s 20us/step - loss: 43089965245.9721 - val_loss: 41900260516.3457\n",
      "Epoch 52/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 42768341360.6319 - val_loss: 41555012018.8839\n",
      "Epoch 53/400\n",
      "15117/15117 [==============================] - 0s 22us/step - loss: 42459819310.3499 - val_loss: 41246021596.6025\n",
      "Epoch 54/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 42149387781.3175 - val_loss: 40942444564.2272\n",
      "Epoch 55/400\n",
      "15117/15117 [==============================] - 0s 19us/step - loss: 41865183735.1602 - val_loss: 40703299578.9432\n",
      "Epoch 56/400\n",
      "15117/15117 [==============================] - 0s 14us/step - loss: 41581280444.9221 - val_loss: 40431359044.2667\n",
      "Epoch 57/400\n",
      "15117/15117 [==============================] - 0s 16us/step - loss: 41356059694.5362 - val_loss: 40215771823.7235\n",
      "Epoch 58/400\n",
      "15117/15117 [==============================] - 0s 21us/step - loss: 41149911899.4636 - val_loss: 39968128796.4444\n",
      "Epoch 59/400\n",
      "15117/15117 [==============================] - 0s 22us/step - loss: 40906129422.8347 - val_loss: 39834501135.1704\n",
      "Epoch 60/400\n",
      "15117/15117 [==============================] - 0s 22us/step - loss: 40699559912.9690 - val_loss: 39530927061.0173\n",
      "Epoch 61/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 40505141046.5463 - val_loss: 39329309516.4839\n",
      "Epoch 62/400\n",
      "15117/15117 [==============================] - 0s 19us/step - loss: 40293789244.3210 - val_loss: 39109531339.5358\n",
      "Epoch 63/400\n",
      "15117/15117 [==============================] - 0s 17us/step - loss: 40071107959.3380 - val_loss: 38932526901.7284\n",
      "Epoch 64/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 39847912205.9710 - val_loss: 38676542461.4716\n",
      "Epoch 65/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15117/15117 [==============================] - 0s 17us/step - loss: 39632141326.2250 - val_loss: 38467642345.2444\n",
      "Epoch 66/400\n",
      "15117/15117 [==============================] - 0s 24us/step - loss: 39405294154.9524 - val_loss: 38227277889.7383\n",
      "Epoch 67/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 39166099815.2840 - val_loss: 37998723304.6123\n",
      "Epoch 68/400\n",
      "15117/15117 [==============================] - 0s 23us/step - loss: 38944911035.1271 - val_loss: 37771973007.4864\n",
      "Epoch 69/400\n",
      "15117/15117 [==============================] - 0s 24us/step - loss: 38742249439.7566 - val_loss: 37533077276.4444\n",
      "Epoch 70/400\n",
      "15117/15117 [==============================] - 0s 20us/step - loss: 38523557354.3576 - val_loss: 37318463427.3185\n",
      "Epoch 71/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 38287861538.7667 - val_loss: 37109253279.2889\n",
      "Epoch 72/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 38103843158.0785 - val_loss: 36895869544.9284\n",
      "Epoch 73/400\n",
      "15117/15117 [==============================] - 0s 20us/step - loss: 37879932800.5165 - val_loss: 36662448512.3160\n",
      "Epoch 74/400\n",
      "15117/15117 [==============================] - 0s 24us/step - loss: 37697411377.2288 - val_loss: 36461116666.3111\n",
      "Epoch 75/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 37470386516.9946 - val_loss: 36224925483.6148\n",
      "Epoch 76/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 37287016649.8602 - val_loss: 36091587217.3827\n",
      "Epoch 77/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 37113550393.6114 - val_loss: 35850903283.9901\n",
      "Epoch 78/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 36938237826.8196 - val_loss: 35669569596.6815\n",
      "Epoch 79/400\n",
      "15117/15117 [==============================] - 0s 23us/step - loss: 36774978422.0171 - val_loss: 35507060998.9531\n",
      "Epoch 80/400\n",
      "15117/15117 [==============================] - 0s 20us/step - loss: 36616363951.2898 - val_loss: 35344354862.7753\n",
      "Epoch 81/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 36533750108.5813 - val_loss: 35215785185.0272\n",
      "Epoch 82/400\n",
      "15117/15117 [==============================] - 0s 21us/step - loss: 36342147359.4814 - val_loss: 35061589414.2420\n",
      "Epoch 83/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 36173301858.6270 - val_loss: 34960898477.8272\n",
      "Epoch 84/400\n",
      "15117/15117 [==============================] - 0s 16us/step - loss: 36055193584.0138 - val_loss: 34771755139.4765\n",
      "Epoch 85/400\n",
      "15117/15117 [==============================] - 0s 15us/step - loss: 35907642653.7202 - val_loss: 34633242173.9457\n",
      "Epoch 86/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 35798181073.3791 - val_loss: 34519471880.2173\n",
      "Epoch 87/400\n",
      "15117/15117 [==============================] - 0s 24us/step - loss: 35684408114.5497 - val_loss: 34417613963.0617\n",
      "Epoch 88/400\n",
      "15117/15117 [==============================] - 0s 23us/step - loss: 35575403717.2540 - val_loss: 34274278918.3210\n",
      "Epoch 89/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 35463437552.1323 - val_loss: 34176490281.0864\n",
      "Epoch 90/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 35361903741.1127 - val_loss: 34076624557.1951\n",
      "Epoch 91/400\n",
      "15117/15117 [==============================] - 0s 16us/step - loss: 35252860758.5188 - val_loss: 33976516188.2864\n",
      "Epoch 92/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 35159377539.3107 - val_loss: 33902492977.9358\n",
      "Epoch 93/400\n",
      "15117/15117 [==============================] - 0s 21us/step - loss: 35057176264.3022 - val_loss: 33774440614.8741\n",
      "Epoch 94/400\n",
      "15117/15117 [==============================] - 0s 20us/step - loss: 35066270938.0496 - val_loss: 33674533870.3012\n",
      "Epoch 95/400\n",
      "15117/15117 [==============================] - 0s 22us/step - loss: 34912085285.6456 - val_loss: 33604875382.8346\n",
      "Epoch 96/400\n",
      "15117/15117 [==============================] - 0s 23us/step - loss: 34806137310.3679 - val_loss: 33527821339.8124\n",
      "Epoch 97/400\n",
      "15117/15117 [==============================] - 0s 23us/step - loss: 34734563708.2829 - val_loss: 33514591103.0519\n",
      "Epoch 98/400\n",
      "15117/15117 [==============================] - 0s 24us/step - loss: 34642372839.2586 - val_loss: 33446915332.4247\n",
      "Epoch 99/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 34584845345.5305 - val_loss: 33275989308.0494\n",
      "Epoch 100/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 34495963828.8274 - val_loss: 33220741448.6914\n",
      "Epoch 101/400\n",
      "15117/15117 [==============================] - 0s 24us/step - loss: 34444759172.9026 - val_loss: 33175957043.8321\n",
      "Epoch 102/400\n",
      "15117/15117 [==============================] - 0s 24us/step - loss: 34380224559.8910 - val_loss: 33112423284.9383\n",
      "Epoch 103/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 34310551336.5922 - val_loss: 33028966314.0346\n",
      "Epoch 104/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 34239472403.1191 - val_loss: 32979343597.6691\n",
      "Epoch 105/400\n",
      "15117/15117 [==============================] - 0s 19us/step - loss: 34189929971.5700 - val_loss: 32911643422.9728\n",
      "Epoch 106/400\n",
      "15117/15117 [==============================] - 0s 16us/step - loss: 34127226965.0793 - val_loss: 32874255124.8593\n",
      "Epoch 107/400\n",
      "15117/15117 [==============================] - 0s 16us/step - loss: 34083975084.6141 - val_loss: 32765397988.1876\n",
      "Epoch 108/400\n",
      "15117/15117 [==============================] - 0s 19us/step - loss: 34031371077.5164 - val_loss: 32724836736.3160\n",
      "Epoch 109/400\n",
      "15117/15117 [==============================] - 0s 16us/step - loss: 33979738946.9424 - val_loss: 32886389656.3358\n",
      "Epoch 110/400\n",
      "15117/15117 [==============================] - 0s 14us/step - loss: 33996782041.2198 - val_loss: 32690403494.8741\n",
      "Epoch 111/400\n",
      "15117/15117 [==============================] - 0s 19us/step - loss: 33889521437.4154 - val_loss: 32582868016.0395\n",
      "Epoch 112/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 33869281715.3541 - val_loss: 32499296139.6938\n",
      "Epoch 113/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 33809394133.3587 - val_loss: 32461700745.7975\n",
      "Epoch 114/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 33763954860.3940 - val_loss: 32472037446.7951\n",
      "Epoch 115/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 33749019845.0507 - val_loss: 32397314336.2370\n",
      "Epoch 116/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 33662314669.2746 - val_loss: 32458255524.3457\n",
      "Epoch 117/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 33624868126.6008 - val_loss: 32278226665.8765\n",
      "Epoch 118/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 33576418659.6939 - val_loss: 32208100556.8000\n",
      "Epoch 119/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 33539740545.1261 - val_loss: 32162803626.0346\n",
      "Epoch 120/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 33513982910.1922 - val_loss: 32124530222.7753\n",
      "Epoch 121/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 33439799506.1242 - val_loss: 32069922841.2840\n",
      "Epoch 122/400\n",
      "15117/15117 [==============================] - 0s 21us/step - loss: 33433398654.9247 - val_loss: 32028114964.2272\n",
      "Epoch 123/400\n",
      "15117/15117 [==============================] - 0s 23us/step - loss: 33395427815.6481 - val_loss: 31982563434.1926\n",
      "Epoch 124/400\n",
      "15117/15117 [==============================] - 0s 24us/step - loss: 33369979051.9198 - val_loss: 31960120327.5852\n",
      "Epoch 125/400\n",
      "15117/15117 [==============================] - 0s 19us/step - loss: 33352480863.7820 - val_loss: 31907313886.4988\n",
      "Epoch 126/400\n",
      "15117/15117 [==============================] - 0s 20us/step - loss: 33270110235.6372 - val_loss: 31865016598.1235\n",
      "Epoch 127/400\n",
      "15117/15117 [==============================] - 0s 17us/step - loss: 33259208562.8334 - val_loss: 31833045103.2494\n",
      "Epoch 128/400\n",
      "15117/15117 [==============================] - 0s 23us/step - loss: 33206243844.9110 - val_loss: 31766695056.1185\n",
      "Epoch 129/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15117/15117 [==============================] - 0s 28us/step - loss: 33180879094.0255 - val_loss: 31723221998.3012\n",
      "Epoch 130/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 33143032824.8875 - val_loss: 31699474745.5210\n",
      "Epoch 131/400\n",
      "15117/15117 [==============================] - 0s 28us/step - loss: 33106296076.8533 - val_loss: 31677457987.0025\n",
      "Epoch 132/400\n",
      "15117/15117 [==============================] - 0s 22us/step - loss: 33029834411.0054 - val_loss: 31597768122.4691\n",
      "Epoch 133/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 33066383363.0482 - val_loss: 31786041293.4321\n",
      "Epoch 134/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 33019492321.3484 - val_loss: 31532612544.7901\n",
      "Epoch 135/400\n",
      "15117/15117 [==============================] - 0s 19us/step - loss: 32982375799.0670 - val_loss: 31569098696.3753\n",
      "Epoch 136/400\n",
      "15117/15117 [==============================] - 0s 21us/step - loss: 32927828765.9573 - val_loss: 31624559213.9852\n",
      "Epoch 137/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 32967549951.9323 - val_loss: 31464718315.7728\n",
      "Epoch 138/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 32897706017.8014 - val_loss: 31378505768.4543\n",
      "Epoch 139/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 32864647128.8473 - val_loss: 31390491665.6988\n",
      "Epoch 140/400\n",
      "15117/15117 [==============================] - 0s 22us/step - loss: 32853513730.7434 - val_loss: 31321558605.1161\n",
      "Epoch 141/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 32780872582.6807 - val_loss: 31289371438.1432\n",
      "Epoch 142/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 32796269692.9772 - val_loss: 31315826637.4321\n",
      "Epoch 143/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 32729093828.3395 - val_loss: 31205541387.3778\n",
      "Epoch 144/400\n",
      "15117/15117 [==============================] - 0s 23us/step - loss: 32715478616.6356 - val_loss: 31322181920.2370\n",
      "Epoch 145/400\n",
      "15117/15117 [==============================] - 0s 20us/step - loss: 32719904583.3454 - val_loss: 31141988913.3037\n",
      "Epoch 146/400\n",
      "15117/15117 [==============================] - 0s 19us/step - loss: 32656964921.8316 - val_loss: 31120282874.3111\n",
      "Epoch 147/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 32610035353.3934 - val_loss: 31250638013.6296\n",
      "Epoch 148/400\n",
      "15117/15117 [==============================] - 0s 19us/step - loss: 32577191246.9659 - val_loss: 31057176601.2840\n",
      "Epoch 149/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 32562187606.9590 - val_loss: 31012928969.6395\n",
      "Epoch 150/400\n",
      "15117/15117 [==============================] - 0s 17us/step - loss: 32538484467.7563 - val_loss: 30986848832.4741\n",
      "Epoch 151/400\n",
      "15117/15117 [==============================] - 0s 19us/step - loss: 32532259863.9116 - val_loss: 31005834358.8346\n",
      "Epoch 152/400\n",
      "15117/15117 [==============================] - 0s 16us/step - loss: 32487984028.9666 - val_loss: 30962685335.0716\n",
      "Epoch 153/400\n",
      "15117/15117 [==============================] - 0s 19us/step - loss: 32449331990.6415 - val_loss: 30902606587.5753\n",
      "Epoch 154/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 32420368859.7939 - val_loss: 30876014162.1728\n",
      "Epoch 155/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 32402840558.9977 - val_loss: 30851225493.8074\n",
      "Epoch 156/400\n",
      "15117/15117 [==============================] - 0s 22us/step - loss: 32365363030.9252 - val_loss: 30895178759.5852\n",
      "Epoch 157/400\n",
      "15117/15117 [==============================] - 0s 21us/step - loss: 32371194114.8281 - val_loss: 30816769537.2642\n",
      "Epoch 158/400\n",
      "15117/15117 [==============================] - 0s 15us/step - loss: 32378587574.8088 - val_loss: 30885919498.7457\n",
      "Epoch 159/400\n",
      "15117/15117 [==============================] - 0s 17us/step - loss: 32303136830.5902 - val_loss: 30723012400.6716\n",
      "Epoch 160/400\n",
      "15117/15117 [==============================] - 0s 23us/step - loss: 32314473952.4678 - val_loss: 30698108513.3432\n",
      "Epoch 161/400\n",
      "15117/15117 [==============================] - 0s 21us/step - loss: 32301367525.5651 - val_loss: 30680828859.7333\n",
      "Epoch 162/400\n",
      "15117/15117 [==============================] - 0s 23us/step - loss: 32252280874.8106 - val_loss: 30635909615.5654\n",
      "Epoch 163/400\n",
      "15117/15117 [==============================] - 0s 24us/step - loss: 32212627086.6907 - val_loss: 30604447309.1161\n",
      "Epoch 164/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 32227526857.4537 - val_loss: 30590897053.3926\n",
      "Epoch 165/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 32190671845.8530 - val_loss: 30589746967.3877\n",
      "Epoch 166/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 32182913594.5090 - val_loss: 30564650158.4593\n",
      "Epoch 167/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 32156180674.8831 - val_loss: 30510093289.2444\n",
      "Epoch 168/400\n",
      "15117/15117 [==============================] - 0s 21us/step - loss: 32099827332.6655 - val_loss: 30477274807.3086\n",
      "Epoch 169/400\n",
      "15117/15117 [==============================] - 0s 24us/step - loss: 32103448798.7236 - val_loss: 30443384609.5012\n",
      "Epoch 170/400\n",
      "15117/15117 [==============================] - 0s 19us/step - loss: 32077863532.3474 - val_loss: 30487480987.4963\n",
      "Epoch 171/400\n",
      "15117/15117 [==============================] - 0s 15us/step - loss: 32049352509.9975 - val_loss: 30392363629.9852\n",
      "Epoch 172/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 32046642024.6049 - val_loss: 30391611685.2938\n",
      "Epoch 173/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 32039520844.3411 - val_loss: 30358372523.9309\n",
      "Epoch 174/400\n",
      "15117/15117 [==============================] - 0s 24us/step - loss: 32001963550.6516 - val_loss: 30378676593.1457\n",
      "Epoch 175/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 31971976894.3785 - val_loss: 30337613510.4790\n",
      "Epoch 176/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 31936884394.6667 - val_loss: 30299554484.7802\n",
      "Epoch 177/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 31997519472.4795 - val_loss: 30403586128.9086\n",
      "Epoch 178/400\n",
      "15117/15117 [==============================] - 0s 24us/step - loss: 31923679999.3396 - val_loss: 30268281878.7556\n",
      "Epoch 179/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 31922753530.0390 - val_loss: 30218530694.6370\n",
      "Epoch 180/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 31884175416.6292 - val_loss: 30196491322.1531\n",
      "Epoch 181/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 31857703989.4455 - val_loss: 30187596428.3259\n",
      "Epoch 182/400\n",
      "15117/15117 [==============================] - 0s 20us/step - loss: 31844495890.1200 - val_loss: 30216632785.2247\n",
      "Epoch 183/400\n",
      "15117/15117 [==============================] - 0s 20us/step - loss: 31841173988.1934 - val_loss: 30156887209.4025\n",
      "Epoch 184/400\n",
      "15117/15117 [==============================] - 0s 16us/step - loss: 31820795572.8951 - val_loss: 30105764790.6765\n",
      "Epoch 185/400\n",
      "15117/15117 [==============================] - 0s 14us/step - loss: 31768127738.7672 - val_loss: 30098842641.6988\n",
      "Epoch 186/400\n",
      "15117/15117 [==============================] - 0s 19us/step - loss: 31770847874.8365 - val_loss: 30089318875.3383\n",
      "Epoch 187/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 31774277669.6625 - val_loss: 30140580446.8148\n",
      "Epoch 188/400\n",
      "15117/15117 [==============================] - 0s 22us/step - loss: 31746642116.1701 - val_loss: 30047257334.5185\n",
      "Epoch 189/400\n",
      "15117/15117 [==============================] - 0s 19us/step - loss: 31706045899.8754 - val_loss: 30080278947.7136\n",
      "Epoch 190/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 31702765136.3715 - val_loss: 29999751769.7580\n",
      "Epoch 191/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 31677013155.3171 - val_loss: 29980156252.9185\n",
      "Epoch 192/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 31684279129.2283 - val_loss: 30008152787.1210\n",
      "Epoch 193/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15117/15117 [==============================] - 0s 25us/step - loss: 31655275686.4330 - val_loss: 29921917150.4988\n",
      "Epoch 194/400\n",
      "15117/15117 [==============================] - 0s 17us/step - loss: 31631740756.7576 - val_loss: 29904118523.5753\n",
      "Epoch 195/400\n",
      "15117/15117 [==============================] - 0s 16us/step - loss: 31622483405.6366 - val_loss: 29881770327.8617\n",
      "Epoch 196/400\n",
      "15117/15117 [==============================] - 0s 19us/step - loss: 31577066735.3194 - val_loss: 29933520779.6938\n",
      "Epoch 197/400\n",
      "15117/15117 [==============================] - 0s 23us/step - loss: 31562925906.3190 - val_loss: 29851302823.5062\n",
      "Epoch 198/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 31547430586.4497 - val_loss: 29814198428.7605\n",
      "Epoch 199/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 31581310479.0718 - val_loss: 29805916301.5901\n",
      "Epoch 200/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 31548014567.0723 - val_loss: 29817958521.3630\n",
      "Epoch 201/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 31543799436.5231 - val_loss: 29816592318.2617\n",
      "Epoch 202/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 31530975023.3660 - val_loss: 29827875159.8617\n",
      "Epoch 203/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 31481523901.4979 - val_loss: 29749301875.0420\n",
      "Epoch 204/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 31457826124.4596 - val_loss: 29818728301.3531\n",
      "Epoch 205/400\n",
      "15117/15117 [==============================] - 0s 24us/step - loss: 31473147407.2750 - val_loss: 29723523896.2568\n",
      "Epoch 206/400\n",
      "15117/15117 [==============================] - 0s 21us/step - loss: 31430056547.7447 - val_loss: 29712743340.5630\n",
      "Epoch 207/400\n",
      "15117/15117 [==============================] - 0s 20us/step - loss: 31421961208.1424 - val_loss: 29664131223.7037\n",
      "Epoch 208/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 31422969463.5242 - val_loss: 29654104240.9877\n",
      "Epoch 209/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 31401950708.1119 - val_loss: 29653160552.9284\n",
      "Epoch 210/400\n",
      "15117/15117 [==============================] - 0s 24us/step - loss: 31376077567.8137 - val_loss: 29637539025.8568\n",
      "Epoch 211/400\n",
      "15117/15117 [==============================] - 0s 20us/step - loss: 31352628712.6642 - val_loss: 29631071532.8790\n",
      "Epoch 212/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 31356870855.4216 - val_loss: 29636079074.9235\n",
      "Epoch 213/400\n",
      "15117/15117 [==============================] - 0s 16us/step - loss: 31374457787.9230 - val_loss: 29658793402.4691\n",
      "Epoch 214/400\n",
      "15117/15117 [==============================] - 0s 20us/step - loss: 31337215842.9826 - val_loss: 29567297743.3284\n",
      "Epoch 215/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 31335764578.4576 - val_loss: 29691364556.8000\n",
      "Epoch 216/400\n",
      "15117/15117 [==============================] - 0s 20us/step - loss: 31276062155.9431 - val_loss: 29559897545.6395\n",
      "Epoch 217/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 31298170127.0210 - val_loss: 29496502873.7580\n",
      "Epoch 218/400\n",
      "15117/15117 [==============================] - 0s 16us/step - loss: 31316513315.5965 - val_loss: 29499275896.0988\n",
      "Epoch 219/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 31258290898.2597 - val_loss: 29545827912.0593\n",
      "Epoch 220/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 31250691311.4549 - val_loss: 29445701591.5457\n",
      "Epoch 221/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 31237732347.8002 - val_loss: 29424964747.0617\n",
      "Epoch 222/400\n",
      "15117/15117 [==============================] - 0s 16us/step - loss: 31225872491.0265 - val_loss: 29416841711.5654\n",
      "Epoch 223/400\n",
      "15117/15117 [==============================] - 0s 20us/step - loss: 31185279920.6784 - val_loss: 29427903182.0642\n",
      "Epoch 224/400\n",
      "15117/15117 [==============================] - 0s 19us/step - loss: 31213547279.4613 - val_loss: 29375617772.4049\n",
      "Epoch 225/400\n",
      "15117/15117 [==============================] - 0s 22us/step - loss: 31170038163.4494 - val_loss: 29381874528.7111\n",
      "Epoch 226/400\n",
      "15117/15117 [==============================] - 0s 23us/step - loss: 31165170634.5545 - val_loss: 29352877088.8691\n",
      "Epoch 227/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 31157229739.3779 - val_loss: 29373604193.9753\n",
      "Epoch 228/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 31142321340.1093 - val_loss: 29339720463.8025\n",
      "Epoch 229/400\n",
      "15117/15117 [==============================] - 0s 19us/step - loss: 31117098587.6838 - val_loss: 29320680455.5852\n",
      "Epoch 230/400\n",
      "15117/15117 [==============================] - 0s 20us/step - loss: 31079689445.3280 - val_loss: 29363998634.0346\n",
      "Epoch 231/400\n",
      "15117/15117 [==============================] - 0s 17us/step - loss: 31119330998.8596 - val_loss: 29296546944.9481\n",
      "Epoch 232/400\n",
      "15117/15117 [==============================] - 0s 17us/step - loss: 31069466327.5772 - val_loss: 29297485232.3556\n",
      "Epoch 233/400\n",
      "15117/15117 [==============================] - 0s 20us/step - loss: 31047763886.7140 - val_loss: 29251585673.7975\n",
      "Epoch 234/400\n",
      "15117/15117 [==============================] - 0s 21us/step - loss: 31120810970.2698 - val_loss: 29261682374.4790\n",
      "Epoch 235/400\n",
      "15117/15117 [==============================] - 0s 21us/step - loss: 31040537827.2620 - val_loss: 29232404333.3531\n",
      "Epoch 236/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 31015549472.3789 - val_loss: 29248252839.5062\n",
      "Epoch 237/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 31030996352.8213 - val_loss: 29237160861.3926\n",
      "Epoch 238/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 31027785117.5424 - val_loss: 29164847842.2914\n",
      "Epoch 239/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 31023844933.2624 - val_loss: 29181831511.8617\n",
      "Epoch 240/400\n",
      "15117/15117 [==============================] - 0s 22us/step - loss: 31018360627.6335 - val_loss: 29175425327.4074\n",
      "Epoch 241/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 30985998400.3514 - val_loss: 29215447510.2815\n",
      "Epoch 242/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 30979441832.1942 - val_loss: 29140491782.3210\n",
      "Epoch 243/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 30960396885.7228 - val_loss: 29117574874.7062\n",
      "Epoch 244/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 30961261244.6851 - val_loss: 29171085696.3160\n",
      "Epoch 245/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 30944635708.6427 - val_loss: 29097817151.2099\n",
      "Epoch 246/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 30912230144.0169 - val_loss: 29109417402.4691\n",
      "Epoch 247/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 30917402283.5473 - val_loss: 29139805419.1407\n",
      "Epoch 248/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 30902218165.3863 - val_loss: 29071467517.4716\n",
      "Epoch 249/400\n",
      "15117/15117 [==============================] - 0s 19us/step - loss: 30933612359.6163 - val_loss: 29043852796.2074\n",
      "Epoch 250/400\n",
      "15117/15117 [==============================] - 0s 22us/step - loss: 30879691314.6344 - val_loss: 29087209360.7506\n",
      "Epoch 251/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 30871600764.2659 - val_loss: 29089487753.1654\n",
      "Epoch 252/400\n",
      "15117/15117 [==============================] - 0s 20us/step - loss: 30893455549.4641 - val_loss: 29038395882.5086\n",
      "Epoch 253/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 30857967588.4982 - val_loss: 29040979497.7185\n",
      "Epoch 254/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 30826579840.9229 - val_loss: 29089717452.8000\n",
      "Epoch 255/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 30828646918.6045 - val_loss: 28969082601.8765\n",
      "Epoch 256/400\n",
      "15117/15117 [==============================] - 0s 15us/step - loss: 30832529662.9670 - val_loss: 28978597164.8790\n",
      "Epoch 257/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15117/15117 [==============================] - 0s 20us/step - loss: 30825932137.5193 - val_loss: 28938649923.6346\n",
      "Epoch 258/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 30824956543.0432 - val_loss: 28908592656.4346\n",
      "Epoch 259/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 30792299150.2166 - val_loss: 28938862753.8173\n",
      "Epoch 260/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 30789095030.7114 - val_loss: 28913199918.1432\n",
      "Epoch 261/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 30746119198.6855 - val_loss: 28919640974.2222\n",
      "Epoch 262/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 30756182515.2313 - val_loss: 28886440775.4272\n",
      "Epoch 263/400\n",
      "15117/15117 [==============================] - 0s 20us/step - loss: 30812109903.1861 - val_loss: 28915701390.8543\n",
      "Epoch 264/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 30741913795.0863 - val_loss: 28859557832.3753\n",
      "Epoch 265/400\n",
      "15117/15117 [==============================] - 0s 15us/step - loss: 30748792363.9283 - val_loss: 28863652795.7333\n",
      "Epoch 266/400\n",
      "15117/15117 [==============================] - 0s 17us/step - loss: 30738511142.4584 - val_loss: 28847569128.6123\n",
      "Epoch 267/400\n",
      "15117/15117 [==============================] - 0s 13us/step - loss: 30712575751.2649 - val_loss: 28884261759.0519\n",
      "Epoch 268/400\n",
      "15117/15117 [==============================] - 0s 15us/step - loss: 30693422118.4076 - val_loss: 28891036507.6543\n",
      "Epoch 269/400\n",
      "15117/15117 [==============================] - 0s 15us/step - loss: 30767731539.6737 - val_loss: 28845860934.7951\n",
      "Epoch 270/400\n",
      "15117/15117 [==============================] - 0s 14us/step - loss: 30698750545.1166 - val_loss: 28823704866.7654\n",
      "Epoch 271/400\n",
      "15117/15117 [==============================] - 0s 17us/step - loss: 30707011793.4468 - val_loss: 28784860491.2198\n",
      "Epoch 272/400\n",
      "15117/15117 [==============================] - 0s 22us/step - loss: 30692932663.2067 - val_loss: 28749481230.5383\n",
      "Epoch 273/400\n",
      "15117/15117 [==============================] - 0s 21us/step - loss: 30685208779.7568 - val_loss: 28753491811.2395\n",
      "Epoch 274/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 30653727307.1557 - val_loss: 28797524827.6543\n",
      "Epoch 275/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 30716013165.4312 - val_loss: 28843104645.3728\n",
      "Epoch 276/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 30651281722.5767 - val_loss: 28718682455.8617\n",
      "Epoch 277/400\n",
      "15117/15117 [==============================] - 0s 23us/step - loss: 30631514184.6155 - val_loss: 28739164134.7160\n",
      "Epoch 278/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 30646928748.6353 - val_loss: 28681074344.1383\n",
      "Epoch 279/400\n",
      "15117/15117 [==============================] - 0s 20us/step - loss: 30608024185.8951 - val_loss: 28678766516.1481\n",
      "Epoch 280/400\n",
      "15117/15117 [==============================] - 0s 14us/step - loss: 30589665466.9577 - val_loss: 28661254290.6469\n",
      "Epoch 281/400\n",
      "15117/15117 [==============================] - 0s 22us/step - loss: 30618977449.8538 - val_loss: 28673652083.6741\n",
      "Epoch 282/400\n",
      "15117/15117 [==============================] - 0s 20us/step - loss: 30562044762.6847 - val_loss: 28649524428.8000\n",
      "Epoch 283/400\n",
      "15117/15117 [==============================] - 0s 21us/step - loss: 30571912141.3995 - val_loss: 28675854927.6444\n",
      "Epoch 284/400\n",
      "15117/15117 [==============================] - 0s 17us/step - loss: 30589659941.1375 - val_loss: 28668811228.6025\n",
      "Epoch 285/400\n",
      "15117/15117 [==============================] - 0s 21us/step - loss: 30555036638.4695 - val_loss: 28603462233.7580\n",
      "Epoch 286/400\n",
      "15117/15117 [==============================] - 0s 21us/step - loss: 30570698800.9071 - val_loss: 28677536998.0840\n",
      "Epoch 287/400\n",
      "15117/15117 [==============================] - 0s 19us/step - loss: 30539412554.7154 - val_loss: 28571660111.0123\n",
      "Epoch 288/400\n",
      "15117/15117 [==============================] - 0s 24us/step - loss: 30546033373.8768 - val_loss: 28566706894.0642\n",
      "Epoch 289/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 30493622659.2599 - val_loss: 28602247911.3481\n",
      "Epoch 290/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 30514238596.6993 - val_loss: 28726829010.4889\n",
      "Epoch 291/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 30534911885.1158 - val_loss: 28527443391.5259\n",
      "Epoch 292/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 30489810109.0915 - val_loss: 28513553542.0049\n",
      "Epoch 293/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 30483554845.3646 - val_loss: 28527559985.9358\n",
      "Epoch 294/400\n",
      "15117/15117 [==============================] - 0s 20us/step - loss: 30493459493.1206 - val_loss: 28511312220.9185\n",
      "Epoch 295/400\n",
      "15117/15117 [==============================] - 0s 22us/step - loss: 30468548383.2443 - val_loss: 28561152854.5975\n",
      "Epoch 296/400\n",
      "15117/15117 [==============================] - 0s 21us/step - loss: 30454097051.7304 - val_loss: 28470788192.0790\n",
      "Epoch 297/400\n",
      "15117/15117 [==============================] - 0s 21us/step - loss: 30451493380.4369 - val_loss: 28480529425.6988\n",
      "Epoch 298/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 30441741262.6865 - val_loss: 28431674845.8667\n",
      "Epoch 299/400\n",
      "15117/15117 [==============================] - 0s 21us/step - loss: 30442799803.7367 - val_loss: 28431332561.8568\n",
      "Epoch 300/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 30430039981.6302 - val_loss: 28411057230.3802\n",
      "Epoch 301/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 30424954039.0966 - val_loss: 28418003469.9062\n",
      "Epoch 302/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 30410210822.1303 - val_loss: 28493298043.2593\n",
      "Epoch 303/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 30412374554.6550 - val_loss: 28381475741.3926\n",
      "Epoch 304/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 30397494462.0737 - val_loss: 28389392849.2247\n",
      "Epoch 305/400\n",
      "15117/15117 [==============================] - 0s 19us/step - loss: 30356153542.3378 - val_loss: 28409667371.6148\n",
      "Epoch 306/400\n",
      "15117/15117 [==============================] - 0s 21us/step - loss: 30376019046.9622 - val_loss: 28387644681.4815\n",
      "Epoch 307/400\n",
      "15117/15117 [==============================] - 0s 23us/step - loss: 30341690551.6386 - val_loss: 28411604506.5481\n",
      "Epoch 308/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 30341477859.7193 - val_loss: 28324054751.7630\n",
      "Epoch 309/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 30351756253.3857 - val_loss: 28320045258.2716\n",
      "Epoch 310/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 30336164598.8723 - val_loss: 28299695217.7778\n",
      "Epoch 311/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 30337324285.0026 - val_loss: 28297530785.1852\n",
      "Epoch 312/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 30333910135.5581 - val_loss: 28308680516.8988\n",
      "Epoch 313/400\n",
      "15117/15117 [==============================] - 0s 20us/step - loss: 30311515631.5057 - val_loss: 28261537422.8543\n",
      "Epoch 314/400\n",
      "15117/15117 [==============================] - 0s 17us/step - loss: 30363544208.1133 - val_loss: 28262182502.4000\n",
      "Epoch 315/400\n",
      "15117/15117 [==============================] - 0s 22us/step - loss: 30286572451.1308 - val_loss: 28296674043.5753\n",
      "Epoch 316/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 30283702190.4431 - val_loss: 28348567491.3185\n",
      "Epoch 317/400\n",
      "15117/15117 [==============================] - 0s 21us/step - loss: 30309965623.9010 - val_loss: 28217163305.7185\n",
      "Epoch 318/400\n",
      "15117/15117 [==============================] - 0s 23us/step - loss: 30237974083.8399 - val_loss: 28232991397.6099\n",
      "Epoch 319/400\n",
      "15117/15117 [==============================] - 0s 15us/step - loss: 30307513007.8148 - val_loss: 28187193566.4988\n",
      "Epoch 320/400\n",
      "15117/15117 [==============================] - 0s 24us/step - loss: 30251384565.9239 - val_loss: 28277447945.4815\n",
      "Epoch 321/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15117/15117 [==============================] - 0s 27us/step - loss: 30286417656.0916 - val_loss: 28219088456.0593\n",
      "Epoch 322/400\n",
      "15117/15117 [==============================] - 0s 14us/step - loss: 30309858898.5391 - val_loss: 28163127938.2123\n",
      "Epoch 323/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 30233272652.5951 - val_loss: 28184599443.2790\n",
      "Epoch 324/400\n",
      "15117/15117 [==============================] - 0s 23us/step - loss: 30227254160.7060 - val_loss: 28166607070.4988\n",
      "Epoch 325/400\n",
      "15117/15117 [==============================] - 0s 14us/step - loss: 30193059344.0201 - val_loss: 28157316998.6370\n",
      "Epoch 326/400\n",
      "15117/15117 [==============================] - 0s 15us/step - loss: 30204357681.6522 - val_loss: 28148653771.5358\n",
      "Epoch 327/400\n",
      "15117/15117 [==============================] - 0s 23us/step - loss: 30210576025.1902 - val_loss: 28181533870.4593\n",
      "Epoch 328/400\n",
      "15117/15117 [==============================] - 0s 20us/step - loss: 30185472342.9590 - val_loss: 28146384248.7309\n",
      "Epoch 329/400\n",
      "15117/15117 [==============================] - 0s 19us/step - loss: 30173072984.6356 - val_loss: 28097076883.9111\n",
      "Epoch 330/400\n",
      "15117/15117 [==============================] - 0s 22us/step - loss: 30173927998.0144 - val_loss: 28074793576.9284\n",
      "Epoch 331/400\n",
      "15117/15117 [==============================] - 0s 23us/step - loss: 30168453091.8209 - val_loss: 28117965219.7136\n",
      "Epoch 332/400\n",
      "15117/15117 [==============================] - 0s 15us/step - loss: 30155117331.1191 - val_loss: 28195985574.8741\n",
      "Epoch 333/400\n",
      "15117/15117 [==============================] - 0s 13us/step - loss: 30152259975.9338 - val_loss: 28044502367.4469\n",
      "Epoch 334/400\n",
      "15117/15117 [==============================] - 0s 23us/step - loss: 30159368500.0738 - val_loss: 28095086875.1802\n",
      "Epoch 335/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 30162306729.9893 - val_loss: 28023154318.8543\n",
      "Epoch 336/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 30147869723.1631 - val_loss: 28049570317.9062\n",
      "Epoch 337/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 30142213129.5511 - val_loss: 27976124562.6469\n",
      "Epoch 338/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 30128697004.2246 - val_loss: 27985019739.6543\n",
      "Epoch 339/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 30132683776.0000 - val_loss: 27991993811.7531\n",
      "Epoch 340/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 30106876249.8718 - val_loss: 28071746213.6099\n",
      "Epoch 341/400\n",
      "15117/15117 [==============================] - 0s 23us/step - loss: 30120629959.5571 - val_loss: 27977712945.9358\n",
      "Epoch 342/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 30131264816.3482 - val_loss: 27965782713.8370\n",
      "Epoch 343/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 30082166816.9208 - val_loss: 27927716022.0444\n",
      "Epoch 344/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 30090797125.0931 - val_loss: 27964345735.9012\n",
      "Epoch 345/400\n",
      "15117/15117 [==============================] - 0s 23us/step - loss: 30037499104.2138 - val_loss: 27904595897.2049\n",
      "Epoch 346/400\n",
      "15117/15117 [==============================] - 0s 17us/step - loss: 30033656170.1290 - val_loss: 27900234081.9753\n",
      "Epoch 347/400\n",
      "15117/15117 [==============================] - 0s 17us/step - loss: 30036522134.3113 - val_loss: 27868665537.4222\n",
      "Epoch 348/400\n",
      "15117/15117 [==============================] - 0s 18us/step - loss: 30047998550.6034 - val_loss: 27850192683.6148\n",
      "Epoch 349/400\n",
      "15117/15117 [==============================] - 0s 21us/step - loss: 30022537201.5040 - val_loss: 27842552445.1556\n",
      "Epoch 350/400\n",
      "15117/15117 [==============================] - 0s 22us/step - loss: 30001168777.1531 - val_loss: 27906038564.0296\n",
      "Epoch 351/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 30000673367.3485 - val_loss: 27899930866.7259\n",
      "Epoch 352/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 30021703504.6594 - val_loss: 27829735747.6346\n",
      "Epoch 353/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 29980224252.2236 - val_loss: 27916844337.9358\n",
      "Epoch 354/400\n",
      "15117/15117 [==============================] - 0s 20us/step - loss: 30012254315.1620 - val_loss: 27844899984.1185\n",
      "Epoch 355/400\n",
      "15117/15117 [==============================] - 0s 15us/step - loss: 29984574842.9958 - val_loss: 27807975257.1259\n",
      "Epoch 356/400\n",
      "15117/15117 [==============================] - 0s 16us/step - loss: 29963084261.5482 - val_loss: 27791534171.0222\n",
      "Epoch 357/400\n",
      "15117/15117 [==============================] - 0s 14us/step - loss: 30010747998.9014 - val_loss: 27778123740.6025\n",
      "Epoch 358/400\n",
      "15117/15117 [==============================] - 0s 16us/step - loss: 29912136223.8709 - val_loss: 27796766937.4420\n",
      "Epoch 359/400\n",
      "15117/15117 [==============================] - 0s 23us/step - loss: 30001270209.4437 - val_loss: 27803645097.4025\n",
      "Epoch 360/400\n",
      "15117/15117 [==============================] - 0s 24us/step - loss: 29973505920.2456 - val_loss: 27744023311.8025\n",
      "Epoch 361/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 29907179610.6339 - val_loss: 27718019142.7951\n",
      "Epoch 362/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 29953332912.1535 - val_loss: 27697513616.1185\n",
      "Epoch 363/400\n",
      "15117/15117 [==============================] - 0s 24us/step - loss: 29884757529.7744 - val_loss: 27709389467.4963\n",
      "Epoch 364/400\n",
      "15117/15117 [==============================] - 0s 23us/step - loss: 29888293303.5539 - val_loss: 27793082671.4074\n",
      "Epoch 365/400\n",
      "15117/15117 [==============================] - 0s 24us/step - loss: 29956703668.8443 - val_loss: 27676570161.3037\n",
      "Epoch 366/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 29881384764.6427 - val_loss: 27663401339.2593\n",
      "Epoch 367/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 29884119443.6526 - val_loss: 27738063176.6914\n",
      "Epoch 368/400\n",
      "15117/15117 [==============================] - 0s 31us/step - loss: 29852087336.3043 - val_loss: 27666328153.7580\n",
      "Epoch 369/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 29864989253.0592 - val_loss: 27623123318.2025\n",
      "Epoch 370/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 29885065092.3098 - val_loss: 27903726382.1432\n",
      "Epoch 371/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 29867071720.2069 - val_loss: 27655036068.3457\n",
      "Epoch 372/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 29833361247.3247 - val_loss: 27606501290.0346\n",
      "Epoch 373/400\n",
      "15117/15117 [==============================] - 0s 23us/step - loss: 29832590395.0001 - val_loss: 27577169864.3753\n",
      "Epoch 374/400\n",
      "15117/15117 [==============================] - 0s 21us/step - loss: 29862452913.3728 - val_loss: 27601685031.1901\n",
      "Epoch 375/400\n",
      "15117/15117 [==============================] - 0s 24us/step - loss: 29798122556.8967 - val_loss: 27670283413.1753\n",
      "Epoch 376/400\n",
      "15117/15117 [==============================] - 0s 28us/step - loss: 29815293792.0699 - val_loss: 27637146818.6864\n",
      "Epoch 377/400\n",
      "15117/15117 [==============================] - 0s 30us/step - loss: 29820084625.2817 - val_loss: 27529363531.8519\n",
      "Epoch 378/400\n",
      "15117/15117 [==============================] - 0s 24us/step - loss: 29814790847.1914 - val_loss: 27521420416.9481\n",
      "Epoch 379/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 29785367285.4498 - val_loss: 27551216597.0173\n",
      "Epoch 380/400\n",
      "15117/15117 [==============================] - 0s 28us/step - loss: 29764825740.1844 - val_loss: 27549339258.6272\n",
      "Epoch 381/400\n",
      "15117/15117 [==============================] - 0s 32us/step - loss: 29817184759.1601 - val_loss: 27516621892.2667\n",
      "Epoch 382/400\n",
      "15117/15117 [==============================] - 0s 29us/step - loss: 29748869270.9887 - val_loss: 27512333997.1951\n",
      "Epoch 383/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 29749162450.2428 - val_loss: 27529546835.4370\n",
      "Epoch 384/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 29766724457.4516 - val_loss: 27480635179.6148\n",
      "Epoch 385/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15117/15117 [==============================] - 0s 23us/step - loss: 29712230639.6581 - val_loss: 27506744550.0840\n",
      "Epoch 386/400\n",
      "15117/15117 [==============================] - 0s 20us/step - loss: 29777173240.8367 - val_loss: 27517980818.6469\n",
      "Epoch 387/400\n",
      "15117/15117 [==============================] - 0s 20us/step - loss: 29746650434.5021 - val_loss: 27505125219.2395\n",
      "Epoch 388/400\n",
      "15117/15117 [==============================] - 0s 23us/step - loss: 29756074838.1801 - val_loss: 27458460229.5309\n",
      "Epoch 389/400\n",
      "15117/15117 [==============================] - 0s 28us/step - loss: 29737305140.1585 - val_loss: 27466891921.3827\n",
      "Epoch 390/400\n",
      "15117/15117 [==============================] - 0s 24us/step - loss: 29739565414.2002 - val_loss: 27428554671.0914\n",
      "Epoch 391/400\n",
      "15117/15117 [==============================] - 0s 24us/step - loss: 29736421141.4900 - val_loss: 27421123166.8148\n",
      "Epoch 392/400\n",
      "15117/15117 [==============================] - 0s 24us/step - loss: 29699085578.7535 - val_loss: 27435516702.9728\n",
      "Epoch 393/400\n",
      "15117/15117 [==============================] - 0s 24us/step - loss: 29667580608.4784 - val_loss: 27440662674.6469\n",
      "Epoch 394/400\n",
      "15117/15117 [==============================] - 0s 24us/step - loss: 29663954467.7997 - val_loss: 27391266128.2765\n",
      "Epoch 395/400\n",
      "15117/15117 [==============================] - 0s 28us/step - loss: 29657109872.5641 - val_loss: 27487176213.4914\n",
      "Epoch 396/400\n",
      "15117/15117 [==============================] - 0s 24us/step - loss: 29645312381.3328 - val_loss: 27370450979.3975\n",
      "Epoch 397/400\n",
      "15117/15117 [==============================] - 0s 25us/step - loss: 29650181044.8782 - val_loss: 27363804521.5605\n",
      "Epoch 398/400\n",
      "15117/15117 [==============================] - 0s 29us/step - loss: 29676578213.4000 - val_loss: 27363451648.6321\n",
      "Epoch 399/400\n",
      "15117/15117 [==============================] - 0s 27us/step - loss: 29616691930.6254 - val_loss: 27356577352.0593\n",
      "Epoch 400/400\n",
      "15117/15117 [==============================] - 0s 26us/step - loss: 29635087331.6854 - val_loss: 27342254322.7259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e74bb389e8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,y=y_train.values,\n",
    "         validation_data=(X_test,y_test.values),\n",
    "         batch_size=128,epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses=pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e74ffd8470>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evalution on test data\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,explained_variance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1       , 0.08      , 0.04239917, ..., 0.00887725, 0.63636364,\n",
       "        0.        ],\n",
       "       [0.3       , 0.36      , 0.17269907, ..., 0.00993734, 0.81818182,\n",
       "        0.        ],\n",
       "       [0.2       , 0.24      , 0.12512927, ..., 0.00547073, 0.90909091,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.1       , 0.08      , 0.05584281, ..., 0.00506255, 1.        ,\n",
       "        0.        ],\n",
       "       [0.3       , 0.2       , 0.22233713, ..., 0.00774485, 0.09090909,\n",
       "        1.        ],\n",
       "       [0.3       , 0.32      , 0.27611169, ..., 0.0196531 , 0.45454545,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function sklearn.metrics.regression.mean_absolute_error(y_true, y_pred, sample_weight=None, multioutput='uniform_average')>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165354.9337155796"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7938637362681527"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yashraj\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:2064: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  x[:, None]\n",
      "C:\\Users\\Yashraj\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages\\matplotlib\\axes\\_base.py:248: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  x = x[:, np.newaxis]\n",
      "C:\\Users\\Yashraj\\anaconda3\\envs\\python-cvcourse\\lib\\site-packages\\matplotlib\\axes\\_base.py:250: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  y = y[:, np.newaxis]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e750030c18>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#out predictions\n",
    "plt.scatter(y_test,predictions)\n",
    "\n",
    "#perfect predictions\n",
    "plt.plot(y_test,y_test,\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
