import numpy as np
import matplotlib.pyplot as plt
#step 2: create syntheic dataset generates 100 random values betwwen -0.5 and 0.5
#the target variable is a non-linear function:y=3x+noise
#the noise is added with 0.05*np.random.randn(100)to simulate real_world data
np.random.seed(42)
X=np.random.rand(100,1) - 0.5
y=3*X[:,0]**2+ 0.05*np.random.randn(100)
#step 3:store in dtaframe and plot store X and y into dataframe.plot the scatterplot of the data to visualize the relationsip

import pandas as pd
df=pd.DataFrame()
df["X"]=X.reshape(100)
df["y"]=y
df

plt.scatter(df["X"],df["y"])
plt.title("X vs Y")

df["pred1"]=df["y"].mean()
df
df["res1"]=df["y"] - df["pred1"]
df

plt.scatter(df["X"],df["y"])
plt.plot(df["X"],df["pred1"],color="red")

from sklearn.tree import DecisionTreeRegressor
tree1=DecisionTreeRegressor(max_leaf_nodes=8)
tree1.fit(df["X"].values.reshape(100,1),df["res1"].values)

from sklearn.tree import plot_tree
plot_tree(tree1)
plt.show()

X_test=np.linspace(-0.5,0.5,500)
y_pred=0.265458+tree1.predict(X_test.reshape(500,1))

plt.figure(figsize=(14,4))
plt.subplot(121)
plt.plot(X_test,y_pred,linewidth=2,color="red")
plt.scatter(df["X"],df["y"])

df["pred2"]=0.265458+tree1.predict(df["X"].values.reshape(100,1))
df
df["res2"]=df["y"]-df["pred2"]
df

tree2=DecisionTreeRegressor(max_leaf_nodes=8)
tree2.fit(df["X"].values.reshape(100,1),df["res2"].values)

y_pred=0.265458+sum(regressor.predict(X_test.reshape(-1,1)) for regressor in [tree1,tree2])

plt.figure(figsize=(14,4))
plt.subplot(121)
plt.plot(X_test,y_pred,linewidth=2,color="red")
plt.scatter(df["X"],df["y"])
plt.title("X vs y")

def gradient_boost(X,y,number,lr,count=1,regs=[],foo=None):
    if number == 0:
        return
    else:
        
        if count > 1:
            y=y-regs[-1].predict(X)
        else:
            foo=y
            
            
        tree_reg=DecisionTreeRegressor(max_depth=5,random_state=42)
        tree_reg.fit(X,y)
        
        regs.append(tree_reg)
        
        x1=np.linspace(-0.5,0.5,500)
        y_pred=sum(lr*regressor.predict(x1.reshape(-1,1)) for regressor in regs)
        
        print(number)
        plt.figure()
        plt.plot(x1,y_pred,linewidth=2)
        plt.plot(X[:,0],foo,"r.")
        plt.show()
        
        gradient_boost(X, y, number-1, lr,count+1,regs,foo=foo)
        
np.random.seed(42)
X=np.random.rand(100,1)-0.5
y=3*X[:,0]**2+0.05*np.random(100)
gradient_boost(X,y,5,lr=1)
 